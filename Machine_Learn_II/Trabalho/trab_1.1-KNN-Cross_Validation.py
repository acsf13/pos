import pandas as pd
import numpy as np
from sklearn.model_selection import cross_val_score, KFold
from sklearn.neighbors import KNeighborsClassifier
from sklearn.preprocessing import StandardScaler, LabelEncoder
import matplotlib.pyplot as plt

# Carga e processamento dos dados
df_gym = pd.read_csv('C:/Users/Antonio/Desktop/projeto-pos/pos/Machine_Learn_II/Trabalho/gym.csv')

# Checar valores ausentes
missing_values = df_gym.isnull().sum()
print(f"Valores ausentes:\n{missing_values}\n")

# Remover linhas com valores ausentes na vari√°vel alvo
df_gym = df_gym.dropna(subset=['Experience_Level'])

# Codificar vari√°veis categ√≥ricas
label_encoders = {}
categorical_columns = ['Gender', 'Workout_Type']
for col in categorical_columns:
    le = LabelEncoder()
    df_gym[col] = le.fit_transform(df_gym[col])
    label_encoders[col] = le

# Definir features (X) e target (y)
X = df_gym.drop(columns=['Experience_Level'])
y = df_gym['Experience_Level']

# Normalizar os dados
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Configura√ß√£o dos K-Folds
k_folds = 10
kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)

# Testar diferentes valores de k no KNN
k_values = range(1, 31)  # Valores de k entre 1 e 30
mean_scores = []
std_scores = []

for k in k_values:
    knn = KNeighborsClassifier(n_neighbors=k)
    
    # Realizar valida√ß√£o cruzada
    scores = cross_val_score(knn, X_scaled, y, cv=kf, scoring='accuracy')
    
    # Registrar as m√©dias e desvios padr√£o das acur√°cias
    mean_scores.append(scores.mean())
    std_scores.append(scores.std())

# Encontrar o melhor k com base na acur√°cia m√©dia
optimal_k = k_values[np.argmax(mean_scores)]
best_score = max(mean_scores)

print(f"Melhor valor de k: {optimal_k}")
print(f"Acur√°cia m√©dia com valida√ß√£o cruzada para k={optimal_k}: {best_score:.4f}")

# Visualizar os resultados
plt.figure(figsize=(12, 6))
plt.errorbar(k_values, mean_scores, yerr=std_scores, fmt='o-', label='Acur√°cia M√©dia com Valida√ß√£o Cruzada')
plt.axvline(optimal_k, color='red', linestyle='--', label=f'Melhor k = {optimal_k}')
plt.title('Acur√°cia M√©dia vs. N√∫mero de Vizinhos (k) com Valida√ß√£o Cruzada')
plt.xlabel('N√∫mero de Vizinhos (k)')
plt.ylabel('Acur√°cia M√©dia')
plt.legend()
plt.grid(True)
plt.show()

# Explica√ß√£o do C√≥digo:
# K-Folds com KFold:

# O conjunto de dados √© dividido em 10 folds aleat√≥rios.
# Cada fold √© usado como conjunto de teste enquanto os outros 9 s√£o usados para treino.
# Cross-Validation com cross_val_score:

# Avalia o modelo K-NN para cada valor de ùëò
# k.
# Retorna as acur√°cias para cada uma das 10 itera√ß√µes do K-Fold.
# C√°lculo da M√©dia e Desvio Padr√£o:

# Calcula a m√©dia e o desvio padr√£o das acur√°cias obtidas nos 10 folds.
# Identifica√ß√£o do Melhor 
# ùëò
# k:

# Seleciona o 
# ùëò
# k que maximiza a acur√°cia m√©dia.
# Visualiza√ß√£o:

# Um gr√°fico mostra a acur√°cia m√©dia e os intervalos de erro (desvio padr√£o) para cada valor de 
# ùëò
# k.
# Benef√≠cios:
# O modelo √© avaliado de forma robusta, minimizando o impacto de divis√µes espec√≠ficas dos dados.
# O desvio padr√£o ajuda a entender a variabilidade do desempenho para diferentes divis√µes.