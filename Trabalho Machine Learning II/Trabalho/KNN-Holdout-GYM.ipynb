{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load dataset\n",
    "df_gym = pd.read_csv('gym_members_exercise_tracking.csv')\n",
    "df_gym.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "missing_values = df_gym.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing target values, if any\n",
    "data = df_gym.dropna(subset=['Experience_Level'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical variables (Gender, Workout_Type)\n",
    "label_encoders = {}\n",
    "categorical_columns = ['Gender', 'Workout_Type']\n",
    "\n",
    "for col in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    df_gym[col] = le.fit_transform(df_gym[col])\n",
    "    label_encoders[col] = le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gym.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features (X) and target (y)\n",
    "X = df_gym.drop(columns=['Experience_Level'])\n",
    "y = df_gym['Experience_Level']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################\n",
    "#create training and testing datasets. 30% for tests selected by random\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled,y,test_size=0.3,random_state=42,stratify=y)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "\n",
    "print (X_train.shape, y_train.shape)\n",
    "print (X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=10)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# neigh = KNeighborsClassifier(n_neighbors=5,weights='distance')\n",
    "# neigh.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on training and testing sets\n",
    "y_train_pred = knn.predict(X_train)\n",
    "y_test_pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracies\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "test_accuracy  = accuracy_score(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate confusion matrices\n",
    "train_conf_matrix = confusion_matrix(y_train, y_train_pred)\n",
    "test_conf_matrix = confusion_matrix(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display results\n",
    "# uuu\n",
    "results = {\n",
    "    \"Train Accuracy\": train_accuracy,\n",
    "    \"Test Accuracy\": test_accuracy,\n",
    "    \"Train Confusion Matrix\": train_conf_matrix,\n",
    "    \"Test Confusion Matrix\": test_conf_matrix\n",
    "}\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrices\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "# Training confusion matrix\n",
    "sns.heatmap(train_conf_matrix, annot=True, fmt='d', cmap='Greens', ax=axes[0])\n",
    "axes[0].set_title('Training Confusion Matrix')\n",
    "axes[0].set_xlabel('Predicted Labels')\n",
    "axes[0].set_ylabel('True Labels')\n",
    "\n",
    "# Testing confusion matrix\n",
    "sns.heatmap(test_conf_matrix, annot=True, fmt='d', cmap='Greens', ax=axes[1])\n",
    "axes[1].set_title('Testing Confusion Matrix')\n",
    "axes[1].set_xlabel('Predicted Labels')\n",
    "axes[1].set_ylabel('True Labels')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para determinar se o modelo está sofrendo de overfitting, podemos comparar a acurácia no conjunto de treinamento com a acurácia no conjunto de teste. Em geral:\n",
    "\n",
    "Overfitting ocorre quando o modelo tem um desempenho significativamente melhor no treinamento do que no teste, indicando que ele está memorizando os dados de treinamento em vez de generalizar bem para novos dados.\n",
    "Boa generalização ocorre quando a diferença entre as acurácias de treinamento e teste é pequena.\n",
    "Resultados:\n",
    "Acurácia no treinamento: 90.75%\n",
    "Acurácia no teste: 81.51%\n",
    "Diferença: 9.24 pontos percentuais\n",
    "Análise:\n",
    "Diferença de acurácia:\n",
    "\n",
    "A diferença de ~9.24% entre o treinamento e o teste indica que o modelo está capturando bem os padrões dos dados, mas ainda tem algum grau de especialização no conjunto de treinamento.\n",
    "Natureza do modelo KNN:\n",
    "\n",
    "O KNN tende a ser mais resiliente ao overfitting, mas ele pode ser influenciado pela escolha de hiperparâmetros, como o número de vizinhos (n_neighbors).\n",
    "Conclusão:\n",
    "Este modelo apresenta uma leve tendência ao overfitting, mas ainda está dentro de uma margem aceitável. Para mitigar isso:\n",
    "\n",
    "Testar valores diferentes para n_neighbors, ajustando para um melhor equilíbrio entre bias e variance.\n",
    "Validar com mais métricas, como F1-score, especialmente se as classes estiverem desbalanceadas.\n",
    "Considerar validação cruzada para avaliar o desempenho médio em diferentes divisões do conjunto de dados."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pos",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
